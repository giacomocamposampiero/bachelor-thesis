{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8abb4479",
   "metadata": {},
   "source": [
    "# Integer linear programming experiments for vertex cover problems\n",
    "// TODO Simple description of the project to add."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92724860",
   "metadata": {},
   "source": [
    "First of all, import the Python libraries used in the process of data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ec5a273",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-af47f16c45d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcurve_fit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpyvis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.optimize import curve_fit\n",
    "import pyvis\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import params as pr\n",
    "from mpl_toolkits import mplot3d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63073aea",
   "metadata": {},
   "source": [
    "Import experimental data from the corresponding csv files. The data are splitted over multiple csv file, one for each graph class studied. The first three rows of one of these files are displayed below, to give an idea of the file structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12963a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "gnp_data = pd.read_csv('data/gnp.csv')\n",
    "bag_data = pd.read_csv('data/bag.csv')\n",
    "rrg_data = pd.read_csv('data/rrg.csv')\n",
    "wsg_data = pd.read_csv('data/wsg.csv')\n",
    "gnp_data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac274bc1",
   "metadata": {},
   "source": [
    "## Erdős–Rényi graphs\n",
    "This chapter reports a detailed analysis of a particular subset of graphs named Erdős–Rényi graphs (also known as binomial graphs) generated using the `gnp_random_graph()` method of the Networkx package. With this method, the inclusion of each edge of the graph depends on a parametric probability *p*, indipendent from every other edge of the graph. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09e84a9",
   "metadata": {},
   "source": [
    "First of all, plot the correlation between the solution time (y axis) versus the average clustering index of the graph (x axis). Graphs with different sizes are labeled with different colors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7738f458",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(pr.GNP_N)):\n",
    "    filter = gnp_data['n'] == pr.GNP_N[i]\n",
    "    data = gnp_data[filter]\n",
    "    plt.scatter(data['p'], data['time'], label=str(pr.GNP_N[i]), marker=\".\")\n",
    "plt.legend(loc=\"best\")\n",
    "\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(12, 6.5)\n",
    "fig.savefig('document/images/gnp-2d.eps', format='eps')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf79deef",
   "metadata": {},
   "source": [
    "Even studying how the size of the graph influences the computational difficulty of the associated LP problem might outline interesting trends related to this specific parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcde4373",
   "metadata": {},
   "outputs": [],
   "source": [
    "def size_impact_gnp(p, ax):\n",
    "    filter = gnp_data['p'] == p\n",
    "    data = gnp_data[filter]\n",
    "    ax.scatter(data['n'], data['time'], marker=\".\")\n",
    "    ax.set_xlabel('n')\n",
    "    ax.set_ylabel('time')\n",
    "    ax.set_title(\" p = \" + str(p))\n",
    "\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3)\n",
    "fig.set_size_inches(16, 5)\n",
    "size_impact_gnp(0.1, ax1)\n",
    "size_impact_gnp(0.5, ax2)\n",
    "size_impact_gnp(0.9, ax3)\n",
    "plt.tight_layout()\n",
    "fig.savefig('document/images/gnp_p.eps', format='eps')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7f6395",
   "metadata": {},
   "source": [
    "To summarize the different graphs given above, plot a 3-dimensional graph comprehensive of all the information and trends analyzed before. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95cebf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(5,5))\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "z = np.ravel(gnp_data['time'])\n",
    "y = np.ravel(gnp_data['n'])\n",
    "x = np.ravel(gnp_data['p'])\n",
    "\n",
    "ax.set_xlabel('p')\n",
    "ax.set_ylabel('n')\n",
    "ax.set_zlabel('time')\n",
    "ax.plot_trisurf(x, y, z, cmap=cm.coolwarm, antialiased=False)\n",
    "\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(12, 6.5)\n",
    "fig.savefig('document/images/gnp-3d.eps', format='eps')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ccdc1d",
   "metadata": {},
   "source": [
    "### Hypothesis\n",
    "The plots above outline an inverse exponential correlation between the probability to generate each edge of the graph *p* and the solution time of the MIP vertex cover instance. Therefore, the probability *p* may represent a key factor in determing the complexity in the computing of the vertex cover set associated to the graph. Also the number of nodes of the graph plays an important role in determing the complexity of the problem, and even in this case the two measures are bounded by an exponential correlation. \n",
    "\n",
    "Deducing the right parameters *a* and *b* of the exponential formula \n",
    "<a href=\"https://www.codecogs.com/eqnedit.php?latex=y&space;=&space;ae^{-bx}\" target=\"_blank\"><img src=\"https://latex.codecogs.com/gif.latex?y&space;=&space;ae^{-bx}\" title=\"y = ae^{-bx}\" /></a>\n",
    "\n",
    "might be the next step of the experiments. However, current available data are surely not enough to perform such an elaborate job. In order to compensate this lack, the list of parameters used to generate the Erdős–Rényi graph should be expanded. In particular:\n",
    "* likelihoods list should be expanded, including all the probability values between 0 and 1, sampled using 0.05 steps\n",
    "* node number list might be expanded, including also 300 and 400 dimensions (or varying with a step of 50 nodes) \n",
    "* other 2 random seeds might be added"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbcf3579",
   "metadata": {},
   "source": [
    "## Watts–Strogatz small-world graph\n",
    "Watts-Strogatz graphs are generated using the Watts–Strogatz model (proposed by Duncan J. Watts and Steven Strogatz). This is a random graph generation model that produces graph with small-world properties (e.g. high clustering and short average path length). In this experiments, graph are generated using the `watts_strogatz_graph` method of the Networkx package. \n",
    "\n",
    "The graph generation is composed of three main stages. Firstly, the *n* nodes of the graph are wired together in a ring form. Then, each node is connected to its *k* nearest neighbors (*k-1* if *k* is not even), *k/2* on each side. Finally, rewire each node's *k/2* rightmost edges (with a probability *p*) with a random node of the graph (checks to avoid self-loops and duplicates in this stage).\n",
    "\n",
    "First of all, check the correlation between the solution time (y axis) and the number of initial neighbors of each node *k*, for fixed values of rewiring probability *p*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a00a300",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation_wsg(p, ax):\n",
    "    for i in range(len(pr.WS_N)):\n",
    "        filter = np.logical_and(wsg_data['n'] == pr.WS_N[i], wsg_data['p'] == p)\n",
    "        data = wsg_data[filter]\n",
    "        ax.scatter(data['k'], data['time'], label=str(pr.WS_N[i]), marker=\".\")\n",
    "    ax.set_xlabel('k')\n",
    "    ax.set_ylabel('time')\n",
    "    ax.legend(loc=\"best\")\n",
    "    ax.set_title(\" p = \" + str(p))\n",
    "\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3)\n",
    "fig.set_size_inches(14, 4)\n",
    "correlation_wsg(0.1, ax1)\n",
    "correlation_wsg(0.5, ax2)\n",
    "correlation_wsg(0.9, ax3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505cea97",
   "metadata": {},
   "source": [
    "To better visualize the correlation between all the three parameters used to generate a graph of this type, plot a 3-dimensional scatter graph where the correlation between solution time, *k*, *p* and size of the graph is displayed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0c727c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.axes(projection='3d')\n",
    "for i in range(len(pr.WS_N)):\n",
    "    filter = wsg_data['n'] == pr.WS_N[i]\n",
    "    data = wsg_data[filter]\n",
    "    p = data['p']\n",
    "    k = data['k']\n",
    "    t = data['time']\n",
    "    ax.scatter(p, k, t, label=pr.WS_N[i], marker=\".\")\n",
    "    \n",
    "ax.set_xlabel('p')\n",
    "ax.set_ylabel('k')\n",
    "ax.set_zlabel('time')\n",
    "ax.legend(loc=\"upper left\")\n",
    "\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(12, 6.5)\n",
    "#fig.savefig('prova.svg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc3e1ee",
   "metadata": {},
   "source": [
    "### Hypothesis\n",
    "In this case, the combination of high rewiring probability and high number of nodes initially wired together seems to have the higher impact on the computation time needed by CPLEX in order to solve the problem. \n",
    "\n",
    "Even in this case, current available data are surely not enough to perform such an elaborate job. In order to compensate this lack, the list of parameters used to generate the Watts-Strogatz graph should be expanded. In particular:\n",
    "* probabilities list should be expanded, including all the probability values between 0 and 1, sampled using 0.05 steps\n",
    "* number of initial nodes wired together *k* might be expanded\n",
    "* node number list might be expanded, including also 300 and 400 dimensions (optional)\n",
    "* other 2 random seeds might be added"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d547a50",
   "metadata": {},
   "source": [
    "## Regular graphs\n",
    "Regular graphs are a particular class of graphs where each vertex has the same number of neighbors. In graph theory, a regular graph where every vertex has degree *k* is also known as *k*-regular graph.\n",
    "\n",
    "First of all, plot the correlation between the number of edges for each vertex *d* and the solution time required, for each dimension of the graph *n*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aca4f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(pr.RR_N)):\n",
    "    filter = rrg_data['n']==pr.RR_N[i]\n",
    "    data = rrg_data[filter]\n",
    "    plt.scatter(data['d'], data['time'], label=str(pr.RR_N[i]), marker=\".\")\n",
    "plt.legend(loc=\"best\")\n",
    "\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(12, 6.5)\n",
    "#fig.savefig('prova.svg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e7287f",
   "metadata": {},
   "source": [
    "As can be seen from the plot above, there seems to be an exponential correlation between the number of edges per vertex and the computation time required to solve the problem. Moreover, even the size of the graph seems to play a key role in determinating the complexity of the solution, as the exponential curve grows far faster for high-dimensional graphs than for smaller ones. \n",
    "\n",
    "To give a different representation of data plot a 3-dimensional graph as already done for the other categories of graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aab3f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(5,5))\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "z = np.ravel(rrg_data['time'])\n",
    "y = np.ravel(rrg_data['n'])\n",
    "x = np.ravel(rrg_data['d'])\n",
    "\n",
    "ax.set_xlabel('d')\n",
    "ax.set_ylabel('n')\n",
    "ax.set_zlabel('time')\n",
    "ax.plot_trisurf(x, y, z, cmap=cm.coolwarm, antialiased=True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d55d19",
   "metadata": {},
   "source": [
    "### Hypothesis\n",
    "In this particular type of graph the resolution difficulty seems to be highly correlated to the combination of high graph dimensionality and high number of edges wired to each vertex.  \n",
    "\n",
    "However, the data collected by now are not enough to define a general trend, and a more deep analysis may be required in order to deduce a defined trend. Possible expansions of the parameters set might be:\n",
    "* additional graph dimensionalities (step of 50 nodes between 50 and 500 might be good)\n",
    "* more *d* values (especially between 5 and 10)\n",
    "* other 2 random seeds may be added to the seed set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ab8c23",
   "metadata": {},
   "source": [
    "## Barabási–Albert graphs\n",
    "Barabási–Albert graphs are a particular class of graphs generated using the Barabási–Albert model. This algorithm is based on a *preferential attachment* mechanism, which grows the graph by wiring new nodes with *m* edges to the existing nodes of the graph with higher degree. Random graphs generated using this model are particularly similar to many scale-free networks that describe several natural and artificial systems in the real world (e.g. the Internet, citation networks and some social networks). The Barabási–Albert model have therefore the ability to generate networks with hubs (few nodes of the graph with impressively high degree compared to all the other nodes of the same graph). \n",
    "\n",
    "First of all, try to plot the correlation between the avg clustering index and the solution time required for each instance, in order to verify whether there is such a correlation as in the Erdős–Rényi graphs or not. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6dc9d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(pr.BA_M)):\n",
    "    filter = bag_data['m']==pr.BA_M[i]\n",
    "    data = bag_data[filter]\n",
    "    plt.scatter(data['n'], data['time'], label=str(pr.BA_M[i]), marker=\".\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f073763",
   "metadata": {},
   "source": [
    "Then, plot a 3-dimensional graph that displays the combined action of the two parameters used to generate the graphs, the number of nodes and the initial edges wired to each new node, and their effect on the solution time required by CPLEX."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc1afbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(5,5))\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "z = np.ravel(bag_data['time'])\n",
    "y = np.ravel(bag_data['n'])\n",
    "x = np.ravel(bag_data['m'])\n",
    "\n",
    "ax.set_xlabel('m')\n",
    "ax.set_ylabel('n')\n",
    "ax.set_zlabel('time')\n",
    "ax.plot_trisurf(x, y, z, cmap=cm.coolwarm, antialiased=False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c332839b",
   "metadata": {},
   "source": [
    "### Hypothesis\n",
    "In this particular type of graph the resolution difficulty seems to be highly correlated to the combination of high graph dimensionality and high number of edges initially wired to each node.  \n",
    "\n",
    "However, the data collected by now are not enough to define a general trend, and a more deep analysis may be required in order to deduce a defined trend. Possible expansions of the parameters set might be:\n",
    "* additional graph dimensionalities (step of 50 nodes between 50 and 500 might be good)\n",
    "* more *m* values (especially between 5 and 10)\n",
    "* other 2 random seeds may be added to the seed set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91132660",
   "metadata": {},
   "source": [
    "## Overall considerations\n",
    "* Initially, a correlation between the average clustering index of the graph and the solution time was analyzed. However, this parameter have not demonstrated a strong relation with the computational time required to solve the problem. Thus, this hypothesis was discarded.\n",
    "* While for the other categories of graph studied the more edges are created the more complex is the associated vertex cover problem, for Erdős–Rényi graphs seems to be valid the opposite. In fact, for higher values of probability *p* the complexity of the problem decreases. However, this effect might be due to the extremely higher number of edges charateristic of this particular kind of graph, as shown in the plot below. Studying in the details the trend for the case where *n*=100 (which has a number of nodes comparable to that of the other type of graphs), it is possible to see that the complexity of the problem has a maximum in for *p*=0.5, whereas the other two extremes seem to be less difficult to solve (plot below). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e07ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for i in range(len(pr.GNP_N)):\n",
    "    data.append([])\n",
    "    filter = gnp_data['n']==pr.GNP_N[i]\n",
    "    data[i].append(np.average(gnp_data[filter]['edges']))\n",
    "    filter = wsg_data['n']==pr.GNP_N[i]\n",
    "    data[i].append(np.average(wsg_data[filter]['edges']))\n",
    "    filter = rrg_data['n']==pr.GNP_N[i]\n",
    "    data[i].append(np.average(rrg_data[filter]['edges']))\n",
    "    filter = bag_data['n']==pr.GNP_N[i]\n",
    "    data[i].append(np.average(bag_data[filter]['edges']))\n",
    "\n",
    "labels = ['gnp', 'wsg', 'rrg', 'bag']\n",
    "x = np.arange(len(labels))\n",
    "width = 0.25\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(x - 2*width/3, data[0], width, label='100')\n",
    "rects2 = ax.bar(x            , data[1], width, label='200')\n",
    "rects3 = ax.bar(x + 2*width/3, data[2], width, label='500')\n",
    "\n",
    "ax.set_ylabel('edges')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels)\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2b114b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def size_impact_gnp(size, ax):\n",
    "    filter = gnp_data['n'] == size\n",
    "    data = gnp_data[filter]\n",
    "    ax.scatter(data['p'], data['time'], marker=\".\")\n",
    "    ax.set_xlabel(\"p\")\n",
    "    ax.set_ylabel(\"time\")\n",
    "    ax.set_title(\" n = \" + str(size))\n",
    "\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3)\n",
    "fig.set_size_inches(16, 5)\n",
    "size_impact_gnp(100, ax1)\n",
    "size_impact_gnp(150, ax2)\n",
    "size_impact_gnp(200, ax3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fff2695",
   "metadata": {},
   "source": [
    "* The dimension of the graph in each category analized seems to play an important, but not determinant, role. In fact, in all the experiments performed the complexity grows exponentially with the size of the problem. However, it's not the growth of the number of nodes that makes the problem diverge in any of the experiments perfomed (even if it has a key role in amplifiying the action of others determinatig parameters still not identified).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
